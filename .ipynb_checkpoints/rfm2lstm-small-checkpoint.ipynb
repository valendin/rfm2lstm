{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Customer Behavior with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an example implementation of the customer event sequence-to-sequence model as described in the paper \"From RFM to LSTM: Recurrent Neural Networks for Predicting Customer Behavior\" [Valendin et al. 2020].\n",
    "\n",
    "The banking data was taken from https://data.world/lpetrocelli/czech-financial-dataset-real-anonymized-transactions (free account required). In this demo, we will only be using the transaction records, originally found in the trans.csv file from the dataset, also available here in the github repository.\n",
    "\n",
    "This code is not a demonstration of the latest tools offered by the Tensorflow & Keras libraries, it's more of a step by step low level implementation of the model which shows all the details necessary.\n",
    "\n",
    "In Ubuntu linux (tested with 16.04 or 18.04), this is how you prepare a conda environment (called \"tf\" in this example) in order to run this notebook (tested with conda 4.8.0): \n",
    "\n",
    "conda create -y -n tf python==3.8.3\n",
    "pip install pandas numpy tqdm tensorflow tensorflow-addons tensorflow-probability matplotlib IPython jupyter pydot graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from os import cpu_count as core_count\n",
    "from tqdm.auto import tqdm\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "# load the data from the source file\n",
    "# we only need the account_id (a primary key, customer identifier) and the date columns\n",
    "# we also convert the date column from strings like \"930101\" into a proper datetime format\n",
    "# To simplify the task, only consider 1 transaction per day (drop duplicates)\n",
    "\n",
    "df = pd.read_csv(filepath_or_buffer='trans.zip', \n",
    "                 usecols=['account_id', 'date'],\n",
    "                 parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('1998-12-31 00:00:00'), Timestamp('1993-01-01 00:00:00'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['date']), min(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions: 1056320\n",
      "Number of accounts:     4500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display an overview of the dataset\n",
    "\n",
    "print(f\"Number of transactions: {len(df)}\")\n",
    "print(f\"Number of accounts:     {len(df['account_id'].unique())}\")\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.hist(df.date, bins=250)\n",
    "plt.title('Retail Bank Transaction - Overview')\n",
    "plt.show()\n",
    "\n",
    "# display an plot of transaction count per customer distribution\n",
    "\n",
    "transactions_per_account = list(df.groupby('account_id').count()['date'])\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.hist(transactions_per_account, bins=250)\n",
    "plt.title('Transaction counts per account histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the training and holdout period\n",
    "# we will be using 3 years as calibration, to predict the following 3 years\n",
    "\n",
    "training_start = '1993-01-01'\n",
    "training_end   = '1997-12-31'\n",
    "holdout_start  = '1998-01-01'\n",
    "holdout_end    = '1998-12-31'\n",
    "date_format    = '%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare an \"empty\" template dataframe \n",
    "# to be filled with each customer's data\n",
    "\n",
    "# generate a list of dates between two dates\n",
    "def date_range(start, end):\n",
    "    start = datetime.datetime.strptime(start, date_format)\n",
    "    end = datetime.datetime.strptime(end, date_format)\n",
    "    r = (end+datetime.timedelta(days=1)-start).days\n",
    "    return [start+datetime.timedelta(days=i) for i in range(r)]\n",
    "\n",
    "ed = pd.DataFrame(date_range(training_start, holdout_end), columns={'date'})\n",
    "\n",
    "# we subtract 1 here so that the values range from 0 to max-1\n",
    "ed['year'] = ed['date'].dt.year - 1\n",
    "ed['month'] = ed['date'].dt.month - 1\n",
    "ed['week'] = ed['date'].dt.week - 1\n",
    "\n",
    "# save the holdout calendar for later use during prediction\n",
    "holdout_calendar = ed[ed['date'] >= holdout_start].drop(columns=['date']).drop_duplicates().drop(columns=['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202401f280b74f46a6c8d8ff699bf443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='preparing dataset', max=4500.0, style=ProgressStyle(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# samples are training inputs\n",
    "# targets are training labels\n",
    "# calibration is stored for later use in prediction\n",
    "# holdout is data not used in training\n",
    "samples, targets, calibration, holdout = [], [], [], []\n",
    "# total transaction count across all individuals\n",
    "trans = 0\n",
    "max_trans_per_week = 0\n",
    "max_trans_cust = []\n",
    "\n",
    "# shuffle data randomly\n",
    "ids = df['account_id'].unique()\n",
    "random.shuffle(ids)\n",
    "\n",
    "# build a complete record for each customer\n",
    "for account in tqdm(ids, desc='preparing dataset'):\n",
    "    # take the subset of data related to each user, \n",
    "    subset = df.query('account_id == @account').groupby(\n",
    "        ['date']).count().reset_index()\n",
    "    user = subset.copy(deep=True)\n",
    "    user = user.rename(columns={'account_id': 'transactions'})\n",
    "    # grab a copy of the empty frame template\n",
    "    frame = ed.copy(deep=True)\n",
    "    # insert customer ID\n",
    "    frame['account_id'] = account\n",
    "    # merge customer data into the empty frame\n",
    "    frame = frame.merge(user, on=['date'], how='left')\n",
    "    # aggregate weekly transactions\n",
    "    frame = frame.groupby(['year', 'month', 'week']).agg(\n",
    "        {'transactions': 'sum', \n",
    "         'date': 'min'}).sort_values(['date']).reset_index()\n",
    "    # there is a tiny number of cases with 7 transactions per week\n",
    "    # to make the job easier for the model, we clip the value at 6\n",
    "    # frame['transactions'] = frame['transactions'].clip(upper=6)\n",
    "    max_trans = max(frame['transactions'])\n",
    "    max_trans_per_week = max(max_trans_per_week, max_trans)\n",
    "    max_trans_cust.append(max_trans)\n",
    "    # keep a running count of the total transactions\n",
    "    trans += user['transactions'].sum()\n",
    "    # training sequences of everything until the holdout period\n",
    "    training = frame[frame['date'] < holdout_start]\n",
    "    training = training.drop(columns=['date', 'year'])\n",
    "    # store for later use\n",
    "    calibration.append(training)\n",
    "    # training sample: calibration sequence sans the final element\n",
    "    sample = training[:-1].values\n",
    "    samples.append(sample)\n",
    "    # target labels: sequence of transaction counts starting \n",
    "    #  with the 2nd element. At each step of the training\n",
    "    #  we use a row from the train_samples element as our input, \n",
    "    #  and predict the corresponding element from train_targets\n",
    "    target = training.loc[1:, 'transactions'].values\n",
    "    targets.append(target)\n",
    "    # keep holdout sequence to compare with predictions\n",
    "    hold = frame[frame['date'] >= holdout_start]\n",
    "    hold = hold.drop(columns='date')\n",
    "    holdout.append(hold)\n",
    "       \n",
    "# check that we didn't lose any transactions along the way\n",
    "assert trans == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_trans_per_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a validation set which won't be used in training\n",
    "# # we've already shuffled the data so we just grab the tail end\n",
    "# # of the list for validation, the rest is the training set\n",
    "VALIDATION_SPLIT = 0.1\n",
    "validation_size = round(len(samples) * VALIDATION_SPLIT)\n",
    "valid_samples, valid_targets = samples[-validation_size:], targets[-validation_size:]\n",
    "train_samples, train_targets = samples[:-validation_size], targets[:-validation_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def decode_sample(sample, target):\n",
    "    return ({'month'      : tf.cast(tf.expand_dims(sample[:, 0], axis=-1), 'int32'), \n",
    "             'week'       : tf.cast(tf.expand_dims(sample[:, 1], axis=-1), 'int32'), \n",
    "             'transaction': tf.cast(tf.expand_dims(sample[:, 2], axis=-1), 'int32')},\n",
    "             tf.cast(tf.expand_dims(target, axis=-1), 'int32'))\n",
    "\n",
    "# number of samples in each dataset\n",
    "no_train_samples, no_valid_samples = len(train_samples), len(valid_samples)\n",
    "\n",
    "# batch size is the number of samples used to calculate\n",
    "# the loss gradient at each step during the training\n",
    "BATCH_SIZE_TRAIN = 48   # default hyperparameter value\n",
    "BATCH_SIZE_PRED = 250   # for prediction this doesn't matter appart from memory constraint\n",
    "BATCH_SIZE_VALID = no_valid_samples # validation loss calculated in one step\n",
    "BATCH_SIZE_FINETUNE = 128\n",
    "\n",
    "# lenght of each training sequence:\n",
    "seq_len = samples[0].shape[0]\n",
    "\n",
    "train_dataset = (tf.data.Dataset.from_tensor_slices((train_samples, train_targets))\n",
    "                .map(decode_sample)\n",
    "                .batch(BATCH_SIZE_TRAIN)\n",
    "                .repeat())\n",
    "\n",
    "valid_dataset = (tf.data.Dataset.from_tensor_slices((valid_samples, valid_targets))\n",
    "                 .map(decode_sample).batch(BATCH_SIZE_VALID).repeat())\n",
    "\n",
    "all_dataset = (tf.data.Dataset.from_tensor_slices((train_samples+valid_samples, train_targets+valid_targets))\n",
    "                .map(decode_sample)\n",
    "                .batch(BATCH_SIZE_FINETUNE)\n",
    "                .repeat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.__iter__().get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's build the neural network model\n",
    "# first we need to import a bunch of building blocks\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cardinalities of input features\n",
    "max_month = 12\n",
    "max_week = 53\n",
    "\n",
    "# add 1 here since 0 is also a valid weekly transaction count\n",
    "max_trans = int(max_trans_per_week) + 1  \n",
    "\n",
    "# number of units in the memory layer\n",
    "memory_units_A = 128\n",
    "memory_units_B = 0\n",
    "\n",
    "# number of units in the dense layer(s)\n",
    "dense_units_A = 128\n",
    "dense_units_B = 0\n",
    "dense_units_C = 0\n",
    "\n",
    "dense_activation = 'relu'\n",
    "train_learn_rate = 1.0e-3\n",
    "train_clip_norm = 0.8\n",
    "lookahead_sync_period = 5\n",
    "lookahead_step_size = 0.5\n",
    "\n",
    "def emb_size(feature_max: int):\n",
    "    \"\"\" A simple heuristic to determine embedding layer size\"\"\"\n",
    "    return int(np.ceil(feature_max ** 0.5) + 1)\n",
    "\n",
    "\"\"\" input layers map directly to the features from \n",
    "    the input data: month, week, transactions \"\"\"\n",
    "input_month = Input(shape=(seq_len, 1), name='month')\n",
    "input_week = Input(shape=(seq_len, 1), name='week')\n",
    "input_transactions = Input(shape=(seq_len, 1), name='transaction')\n",
    "\n",
    "\"\"\" embedding layers compress signal into a dense real-valued \n",
    "    vector representation. This helps the model extract useful \n",
    "    signals from the input features \"\"\"\n",
    "embedding_month = Embedding(max_month, emb_size(max_month), name='embed_month')\n",
    "embedding_week = Embedding(max_week, emb_size(max_week), name='embed_week')\n",
    "embedding_transactions = Embedding(max_trans, emb_size(max_trans), name='embed_trans')\n",
    "\n",
    "# a simple layer that concatenates a list of vectors\n",
    "concat = Concatenate(axis=-1, name='concat')\n",
    "# a simple layer that removes a dimension from data tensor \n",
    "#  this is needed because the embedding layers introduce \n",
    "#  an extra dimension (of size 1), which we do not need\n",
    "squeeze = Lambda(lambda x: K.squeeze(x, axis=-2), name='squeeze')\n",
    "\n",
    "\"\"\" the LSTM serves as the 'memory' of the model\n",
    "    we define separate LSTM layers for training and prediction models\n",
    "    'stateful' LSTM keeps the internal state (memory) until explicitly deleted\n",
    "    'state-less' LSTM forgets everything after each batch of samples is processed \"\"\"\n",
    "training_memory_layer_A = LSTM(memory_units_A, return_sequences=True, stateful=False, name='lstm_a')\n",
    "training_memory_layer_B = LSTM(memory_units_B, return_sequences=True, stateful=False, name='lstm_b')\n",
    "\n",
    "\"\"\" Dense layers add non-linear compute capacity to the model \"\"\"\n",
    "dense_1 = Dense(dense_units_A, activation=dense_activation, name='dense_a')\n",
    "dense_2 = Dense(dense_units_B, activation=dense_activation, name='dense_b')\n",
    "dense_3 = Dense(dense_units_C, activation=dense_activation, name='dense_c')\n",
    "\n",
    "\"\"\" The final output layer is a softmax prediction layer where\n",
    "    each neuron represents the probability predicting a given \n",
    "    transaction count \"\"\"\n",
    "dense_out = Dense(max_trans, activation='softmax', name='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we assemble the layers into a complete Model\n",
    "# first step is to connect the embedding layers with the inputs\n",
    "emb_month = embedding_month(input_month)\n",
    "emb_week = embedding_week(input_week)\n",
    "emb_trans = embedding_transactions(input_transactions)\n",
    "\n",
    "# we also squeeze out a superfluous dimension from the tensor\n",
    "emb_month = squeeze(emb_month)\n",
    "emb_week = squeeze(emb_week)\n",
    "emb_trans = squeeze(emb_trans)\n",
    "\n",
    "# now we combine embedded vectors into a single long vector\n",
    "output = concat([emb_month, emb_week, emb_trans])\n",
    "\n",
    "# pass the result to the memory layer(s)\n",
    "output = training_memory_layer_A(output)\n",
    "if memory_units_B > 0:\n",
    "    output = training_memory_layer_B(output)\n",
    "\n",
    "# feed-forward through the dense layer(s)\n",
    "output = dense_1(output)\n",
    "if dense_units_B > 0:\n",
    "    output = dense_2(output)\n",
    "if dense_units_C > 0:\n",
    "    output = dense_3(output)\n",
    "\n",
    "# final softmax layer\n",
    "output = dense_out(output)\n",
    "\n",
    "# build the training model\n",
    "training_inputs = [input_month, input_week, input_transactions]\n",
    "model_train = Model(training_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "month (InputLayer)              [(None, 310, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "week (InputLayer)               [(None, 310, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "transaction (InputLayer)        [(None, 310, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embed_month (Embedding)         (None, 310, 1, 5)    60          month[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embed_week (Embedding)          (None, 310, 1, 9)    477         week[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embed_trans (Embedding)         (None, 310, 1, 5)    65          transaction[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "squeeze (Lambda)                multiple             0           embed_month[0][0]                \n",
      "                                                                 embed_week[0][0]                 \n",
      "                                                                 embed_trans[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 310, 19)      0           squeeze[0][0]                    \n",
      "                                                                 squeeze[1][0]                    \n",
      "                                                                 squeeze[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_a (LSTM)                   (None, 310, 128)     75776       concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_a (Dense)                 (None, 310, 128)     16512       lstm_a[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 310, 13)      1677        dense_a[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 94,567\n",
      "Trainable params: 94,567\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_train.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we define the loss function, the optimizer method\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "# from tensorflow_addons.optimizers import NovoGrad\n",
    "\n",
    "optimizer=Adam(learning_rate=train_learn_rate, clipnorm=train_clip_norm)\n",
    "\n",
    "optimizer = tfa.optimizers.Lookahead(\n",
    "    optimizer, sync_period=lookahead_sync_period, slow_step_size=lookahead_step_size)\n",
    "\n",
    "model_train.compile(loss=sparse_categorical_crossentropy, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks are helper functions that control the training flow\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model_weights_filename = 'model_weights.hdf5'\n",
    "\n",
    "callbacks = [\n",
    "            # monitor the validation loss and stop training after\n",
    "            # 'patience' number of epochs during which there is\n",
    "            # no improvement whatsoever, then restore model weights\n",
    "            # from the very best epoch afterwards (epoch with the \n",
    "            # lowest validation loss\n",
    "            EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                min_delta=0.,\n",
    "                restore_best_weights=True,\n",
    "                patience=5,\n",
    "                verbose=1,\n",
    "                mode=\"auto\",\n",
    "            ),\n",
    "            # save model parameters to file whenever the model \n",
    "            # improves (val_loss decreases)\n",
    "            ModelCheckpoint(\n",
    "                model_weights_filename,\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                save_weights_only=True,\n",
    "            )\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "WARNING:tensorflow:From /home/jan/.conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "19/84 [=====>........................] - ETA: 17s - loss: 2.1610"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-97c45d8b077f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mMAX_EPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m history = model_train.fit(train_dataset, \n\u001b[0m\u001b[1;32m      8\u001b[0m                           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Here we run the actual training for a maximum of MAX_EPOCHS\n",
    "# Using a 2018 Thinkpad dual-core laptop, one epoch takes ~30s\n",
    "# With a GeForce 2080Ti, one epoch takes ~2s\n",
    "\n",
    "MAX_EPOCHS = 150\n",
    "\n",
    "history = model_train.fit(train_dataset, \n",
    "                          epochs=MAX_EPOCHS, \n",
    "                          verbose=1,\n",
    "                          shuffle=True,\n",
    "                          callbacks=callbacks,\n",
    "                          validation_data=valid_dataset,\n",
    "                          validation_steps=no_valid_samples//BATCH_SIZE_VALID,\n",
    "                          steps_per_epoch=no_train_samples//BATCH_SIZE_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning tricks: do a few epochs with all data\n",
    "FINETUNING_EPOCHS = 0\n",
    "\n",
    "finetune_optimizer=Adam(learning_rate=0.001)\n",
    "model_train.compile(loss=sparse_categorical_crossentropy, optimizer=finetune_optimizer)\n",
    "\n",
    "finetuning_callbacks = [\n",
    "            # monitor the validation loss and stop training after\n",
    "            # 'patience' number of epochs during which there is\n",
    "            # no improvement whatsoever, then restore model weights\n",
    "            # from the very best epoch afterwards (epoch with the \n",
    "            # lowest validation loss\n",
    "            EarlyStopping(\n",
    "                monitor='loss',\n",
    "                min_delta=0.,\n",
    "                restore_best_weights=True,\n",
    "                patience=5,\n",
    "                verbose=1,\n",
    "                mode=\"auto\",\n",
    "            ),\n",
    "            # save model parameters to file whenever the model \n",
    "            # improves (val_loss decreases)\n",
    "            ModelCheckpoint(\n",
    "                model_weights_filename,\n",
    "                monitor='loss',\n",
    "                save_best_only=True,\n",
    "                save_weights_only=True,\n",
    "            )\n",
    "            ]\n",
    "\n",
    "if FINETUNING_EPOCHS > 0:\n",
    "    history = model_train.fit(all_dataset, \n",
    "                              epochs=FINETUNING_EPOCHS, \n",
    "                              verbose=1,\n",
    "                              shuffle=True,\n",
    "                              callbacks=finetuning_callbacks,\n",
    "                              steps_per_epoch=(no_valid_samples+no_train_samples)//BATCH_SIZE_FINETUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the prediction model is almost identical to the training model\n",
    "# the main difference is that instead of a probability distribution\n",
    "# output, we use a sampling layer to generate future scenarios\n",
    "\n",
    "def sample_multinomial(probs):\n",
    "    \"\"\"\n",
    "    Draws a sample of length 1 from a multinomial distribution with the\n",
    "    given class probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    return tf.cast(\n",
    "        tf.expand_dims(\n",
    "            tfp.distributions.Categorical(probs=probs).sample(), axis=-1\n",
    "        ),\n",
    "        dtype=K.floatx(),\n",
    "    )\n",
    "\n",
    "# sample values from softmax multinomial distribution\n",
    "sample_layer = Lambda(sample_multinomial, name=\"sample_transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Another difference is that we use a \"stateful\" LSTM layer for prediction.\n",
    "    This layer has the exact same size as the LSTM we used in the training model,\n",
    "    hence the same number of parameters, and we will literally copy the parameters\n",
    "    over from the training model. The \"stateful\" property means that the internal\n",
    "    cell state - the \"memories\" of the layer - are kept until we explicitly delete\n",
    "    them. In trainin those are reset to 0 after each sequence is processed - we're \n",
    "    learning from independent histories, so keeping the memories doesn't make sense\n",
    "    there. In prediction however, we need a bit of fine control: we will be feeding\n",
    "    new inputs into the model step by step, so we will also be carefully managing the\n",
    "    memory content ourselves.\n",
    "\"\"\"\n",
    "\n",
    "prediction_memory_layer_A = LSTM(memory_units_A, return_sequences=True, stateful=True, name='lstm_a')\n",
    "prediction_memory_layer_B = LSTM(memory_units_B, return_sequences=True, stateful=True, name='lstm_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use a separate set of Input objects for prediction since the shape of \n",
    "# data is different: \n",
    "# the first dimension is the BATCH_SIZE_PRED\n",
    "# the second dimension is NONE because instead of knowing the length of the \n",
    "# sequence beforehand we want the model to accept sequences of arbitrary length\n",
    "# the last dimension is 1 (1 scalar value per timestep per feature)\n",
    "\n",
    "p_input_month = Input(batch_shape=(BATCH_SIZE_PRED, None, 1), name='month')\n",
    "p_input_week = Input(batch_shape=(BATCH_SIZE_PRED, None, 1), name='week')\n",
    "p_input_transactions = Input(batch_shape=(BATCH_SIZE_PRED, None, 1), name='transaction')\n",
    "\n",
    "# reuse the pretrained embeddings\n",
    "emb_month = embedding_month(p_input_month)\n",
    "emb_week = embedding_week(p_input_week)\n",
    "emb_trans = embedding_transactions(p_input_transactions)\n",
    "\n",
    "# squeeze out a superfluous dimension from the tensor like before\n",
    "emb_month = squeeze(emb_month)\n",
    "emb_week = squeeze(emb_week)\n",
    "emb_trans = squeeze(emb_trans)\n",
    "\n",
    "# combine embedded vectors into a single vector\n",
    "output = concat([emb_month, emb_week, emb_trans])\n",
    "\n",
    "# apply the prediction memory layer\n",
    "output = prediction_memory_layer_A(output)\n",
    "if memory_units_B > 0:\n",
    "    output = prediction_memory_layer_B(output)\n",
    "\n",
    "# feed-forward through the dense layers\n",
    "output = dense_1(output)\n",
    "if dense_units_B > 0:\n",
    "    output = dense_2(output)\n",
    "if dense_units_C > 0:\n",
    "    output = dense_3(output)\n",
    "\n",
    "# softmax layer\n",
    "output = dense_out(output)\n",
    "\n",
    "# apply final sampling layer\n",
    "output = sample_layer(output)\n",
    "\n",
    "# build the prediction model\n",
    "prediction_inputs = [p_input_month, p_input_week, p_input_transactions]\n",
    "model_pred = Model(prediction_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the training and prediction models have the exact same number of parameters\n",
    "assert model_pred.count_params() == model_train.count_params()\n",
    "\n",
    "# check if model has already been trained\n",
    "import os.path\n",
    "\n",
    "if not os.path.exists(model_weights_filename) and os.path.isfile(model_weights_filename):\n",
    "    print('please go back and train a model first')\n",
    "\n",
    "model_pred.load_weights(model_weights_filename, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we can start forecasting, we feed in the entire previous history\n",
    "# for each individual, to build up the cell-state memory which represents\n",
    "# each individual past history. After we feed in the last element of the \n",
    "# training sequence, the model output will be the first forecasted value\n",
    "# for the holdout period. To make things easy, we first put all calibration\n",
    "# data into a individuals*sequence_length*number_of_features shaped tensor.\n",
    "\n",
    "seed = np.array([df.values for df in calibration], dtype=np.float32)\n",
    "seed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_samples = seed.shape[0]\n",
    "no_timesteps = seed.shape[1]\n",
    "no_features = seed.shape[2]\n",
    "no_batches = int(np.ceil(no_samples/BATCH_SIZE_PRED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we probably need to pad the last batch with 0s and then \n",
    "# remove the corresponding predictions after we're done predicting\n",
    "if seed.shape[0] < (BATCH_SIZE_PRED * no_batches):\n",
    "    padding = np.zeros(((BATCH_SIZE_PRED * no_batches) - no_samples, no_timesteps, no_features))\n",
    "    seed = np.concatenate((seed, padding), axis=0)\n",
    "seed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we'll run the prediction 12 times and take the mean to increase robustness\n",
    "# best results usually achieved with 25-35 independent simulations\n",
    "NO_SCENARIOS = 12\n",
    "scenarios = []\n",
    "# how many time-steps does the holdout have\n",
    "holdout_length = holdout[0].shape[0]\n",
    "\n",
    "for _ in tqdm(range(NO_SCENARIOS), desc='predicting'):\n",
    "    batches_predicted = []\n",
    "\n",
    "    for j in range(no_batches):\n",
    "        pred = []\n",
    "        # in the beginning reset the model memory\n",
    "        model_pred.reset_states()\n",
    "        \n",
    "        # calculate batch start and end indexes\n",
    "        batch_start = j * BATCH_SIZE_PRED\n",
    "        batch_end = (j + 1) * BATCH_SIZE_PRED\n",
    "        # batch is a dictionary which links model inputs with lists of sample features\n",
    "        batch = {}        \n",
    "        batch['month'] = seed[batch_start:batch_end, :, 0:1]\n",
    "        batch['week'] = seed[batch_start:batch_end, :, 1:2]\n",
    "        batch['transaction'] = seed[batch_start:batch_end, :, 2:3]        \n",
    "        # pass the batch through the prediction model: here we discard the output\n",
    "        # since we're not interested in in-sample prediction (maybe you are?), we\n",
    "        # just need to build up that internal cell-state memory\n",
    "        prediction = model_pred.predict(batch, batch_size=BATCH_SIZE_PRED)                \n",
    "        # we do however take the very last element of each predicted sequence: \n",
    "        # as this is the first forecasted value\n",
    "        pred.append(prediction[:, -1:, :])\n",
    "\n",
    "        # now lets forecast all the future steps autoregressively\n",
    "        for i in range(holdout_length - 1):\n",
    "            batch = []\n",
    "            for calendar_feature in ['month', 'week']:                        \n",
    "                feature = np.repeat(holdout_calendar.iloc[i][calendar_feature], BATCH_SIZE_PRED)\n",
    "                batch.append(feature[:, np.newaxis, np.newaxis])\n",
    "            batch.append(pred[-1])\n",
    "            \n",
    "            prediction = model_pred.predict(batch, batch_size=BATCH_SIZE_PRED)\n",
    "            pred.append(prediction[:, -1:, :])\n",
    "            \n",
    "        batches_predicted.append(pred)\n",
    "\n",
    "    scenarios.append(batches_predicted)\n",
    "\n",
    "z = []\n",
    "for scenario in scenarios:\n",
    "    y = []\n",
    "    for batch in scenario:\n",
    "        x = []\n",
    "        for time_step in batch:\n",
    "            if type(time_step) == np.ndarray:\n",
    "                x.append(time_step)\n",
    "            else:\n",
    "                complete_time_step = np.concatenate(time_step, axis=-1)\n",
    "                x.append(complete_time_step)\n",
    "        y.append(np.concatenate(x, axis=1))\n",
    "    z.append(np.concatenate(y, axis=0)[:no_samples, :, :])\n",
    "\n",
    "predictions = np.asarray(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "calibration_aggregates = reduce(\n",
    "    lambda x, y: x.add(y, fill_value=0), [i['transactions'] for i in calibration])\n",
    "\n",
    "calibration_aggregates = calibration_aggregates.reset_index()\n",
    "\n",
    "# reuse the index from holdout for prediction\n",
    "predicted_holdout = holdout[0]\n",
    "predicted_holdout['transactions'] = np.squeeze(np.sum(np.mean(predictions, axis=0), axis=0))\n",
    "predicted_holdout = predicted_holdout['transactions'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "plt.plot(calibration_aggregates['index'],\n",
    "         calibration_aggregates['transactions'], color='black')\n",
    "plt.plot(predicted_holdout['index'],\n",
    "         predicted_holdout['transactions'], color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
